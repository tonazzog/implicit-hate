{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f96a11-2e2e-44f8-90ed-2c76653b5585",
   "metadata": {},
   "source": [
    "# Baseline and Tree of Thoughts prompt classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6f24d5-df3c-4ecc-9d19-7b512c8abf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.load.dump import dumps\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic.config import ConfigDict\n",
    "from typing import Annotated, Literal\n",
    "from enum import Enum\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f073a9-3e8b-4a70-af64-1519038910e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d07df1-814f-488a-9ae9-2932a2edbc6e",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7364f9d-0b79-46cd-b97e-a5c0a267bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mistral'\n",
    "model = ChatMistralAI(\n",
    "    model = \"mistral-large-latest\", \n",
    "    temperature = 0.,\n",
    "    api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5102c41-6027-4f9e-8484-08402203bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT API\n",
    "# model_name = 'chatgpt'\n",
    "# model = ChatOpenAI(\n",
    "#     model = 'gpt-4o-mini',\n",
    "#     openai_api_key = os.getenv('OPENAI_API_KEY'), \n",
    "#     temperature = 0.\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d2dddbe-8922-44c6-82fc-a16a0a3916f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama local\n",
    "# model_name = 'qwen'\n",
    "# model = OllamaLLM(model=\"qwen2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558d9d05-f5f7-433d-bebb-28126d256687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen API\n",
    "# model_name = 'qwen'\n",
    "# model = ChatOpenAI(\n",
    "#     model = 'qwen2.5-72b-instruct',\n",
    "#     openai_api_key = os.getenv('DASHSCOPE_API_KEY'), \n",
    "#     openai_api_base = 'https://dashscope-intl.aliyuncs.com/compatible-mode/v1',\n",
    "#     max_tokens = 1024,\n",
    "#     temperature = 0.\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a7272c-794c-46fa-b0af-c3a4b58882d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'deepseek'\n",
    "# model = ChatOpenAI(\n",
    "#     model = 'deepseek-chat', \n",
    "#     openai_api_key= os.getenv('DEEPSEEK_API_KEY'), \n",
    "#     openai_api_base = 'https://api.deepseek.com',\n",
    "#     max_tokens = 1024,\n",
    "#     temperature = 0.\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ea17ae-43ac-4297-8c67-ad3762065bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! How can I assist you today? Let's have a friendly conversation. ðŸ˜Š How are you doing?\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 5, 'total_tokens': 29, 'completion_tokens': 24}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-c6948115-a1ec-4cd6-8270-0fd54db1f2c2-0', usage_metadata={'input_tokens': 5, 'output_tokens': 24, 'total_tokens': 29})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "model.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a795a-7caf-4321-99e8-939f0f6da68c",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bce8b1-605e-4451-b4cb-19ea309177b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True : test con 2 esempi\n",
    "debug_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d0f796-51db-4c6c-9ec3-1072ac01662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_time = 1.1 # impostare se ci sono rate limits, altrimenti lasciare 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8c92473-2ca6-440b-89d1-20be62a95e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = './results/'\n",
    "prompt_folder = './prompts/'\n",
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d052cf-d46e-4ec6-b0c0-57f10a03491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_baseline_stg1_file = result_folder + model_name + '_' + 'result_baseline_stg1.csv'\n",
    "result_baseline_stg2_file = result_folder + model_name + '_' + 'result_baseline_stg2.csv'\n",
    "result_baseline_stg3_file = result_folder + model_name + '_' + 'result_baseline_stg3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6fdd09-c67e-4d10-ba2c-bef2dfa9c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prompt_tot_stg1_file = result_folder + model_name + '_' + 'result_prompt_tot_stg1.csv'\n",
    "result_prompt_tot_stg2_file = result_folder + model_name + '_' + 'result_prompt_tot_stg2.csv'\n",
    "result_prompt_tot_stg3_file = result_folder + model_name + '_' + 'result_prompt_tot_stg3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c960a7-0d06-4d8c-8fd1-053fcb3ecdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompt_folder + 'prompt_tot.txt') as f:\n",
    "    tree_of_thoughts = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14ee755-6088-4047-a5fd-1d794a671c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow this procedure:\n",
      "\n",
      "Imagine three different experts are answering this question.\n",
      "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration.\n",
      "All experts will write down 1 step of their thinking, then share it with the group.\n",
      "They will each critique their response, and the all the responses of others.\n",
      "They will check their answer on based on the nature of the language and intent.\n",
      "Then all experts will go on to the next step and write down this step of their thinking.\n",
      "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts.\n",
      "If at any time they realise that there uncertainty in their logic they will backtrack to where that uncertainty occurred. \n",
      "If any expert realises they're wrong at any point then they acknowledges this and start another train of thought.\n",
      "Each expert will assign a likelihood of their current assertion being correct.\n",
      "Continue until the experts agree on the single most likely classification.\n"
     ]
    }
   ],
   "source": [
    "print(tree_of_thoughts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad84f636-7ddf-4293-938d-646ae657cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(base_prompt, parser):\n",
    "\n",
    "    template = base_prompt + \"\\n\" + \"{format_instructions}'\"  + \"\\n\" + \"Text : '{post}'\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template = template,\n",
    "        input_variables = [\"post\"],\n",
    "        partial_variables = {\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82401d7-01d3-4ac4-bb75-87eff32c4580",
   "metadata": {},
   "source": [
    "## Classification stage 1: High Level Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10d2546d-08dc-40f1-bdfd-30b4a0a1cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateClassification(BaseModel):\n",
    "    hate_class: Literal['implicit_hate','not_hate']\n",
    "    confidence : float\n",
    "    explanation : str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a121e11a-58c0-426c-a65b-74d61e49f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_stage_1(model, df_hate, base_prompt, result_file, initialize = False):\n",
    "    \n",
    "    if initialize:\n",
    "        # Regenerate output file\n",
    "        df = pd.DataFrame(columns = ['post_id', 'class','confidence','explanation'])\n",
    "        df.to_csv(result_file, encoding = \"utf-8\", index = False)\n",
    "    else:\n",
    "        df_elab = pd.read_csv(result_file, encoding = \"utf-8\")\n",
    "        df_hate = df_hate[~df_hate['post_id'].isin(df_elab['post_id'])]\n",
    "        \n",
    "    parser = PydanticOutputParser(pydantic_object = HateClassification)\n",
    "    prompt = get_prompt(base_prompt, parser)\n",
    "    chain = prompt | model | parser\n",
    "\n",
    "    for idx, row in df_hate.iterrows():\n",
    "        \n",
    "        try:            \n",
    "            time.sleep(wait_time)\n",
    "            result = chain.invoke({\"post\": row['post']})\n",
    "    \n",
    "            # Classification stage 1\n",
    "            new_row = {\n",
    "                'post_id': row['post_id'], \n",
    "                'class': result.hate_class, \n",
    "                'confidence': result.confidence,\n",
    "                'explanation': result.explanation\n",
    "            }\n",
    "            df = pd.DataFrame([new_row])\n",
    "            df.to_csv(result_file, encoding = \"utf-8\", mode='a', index=False, header=False)\n",
    "                      \n",
    "        except:\n",
    "            print(\"An exception occurred \" +  str(row['post_id']) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9545d01-0cd0-47e8-a687-898b589661c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompt_folder + 'prompt_stg1.txt') as f:\n",
    "    prompt_stg1 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd7ae4c5-e383-48bb-b081-25af2ede0f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to decide whether the following text can be classified an implicit hate speech or not implicit hate speech.\n",
      "\n",
      "Consider the following definition of hate speech:\n",
      "\n",
      "Hate speech is content that targets individuals or groups with abuse based on their perceived membership in protected categories, including but not limited to race, ethnicity, national origin, caste, sexual orientation, gender, gender identity, religious affiliation, age, disability, or serious disease. \n",
      "Specifically, hate speech can contain:\n",
      "\n",
      "- Hateful References: Content referencing forms of violence or violent events where a protected category was the primary target, intended to harass (e.g., genocides like the Holocaust, lynchings).\n",
      "- Incitement: Content inciting fear, spreading fearful stereotypes, or encouraging others to harass or discriminate against members of protected categories (e.g., asserting that members of a religious group are terrorists, urging others to harass individuals wearing religious symbols).\n",
      "- Slurs and Tropes: Repeated use of slurs, tropes, or content intended to degrade or reinforce negative stereotypes about a protected category.\n",
      "- Dehumanization: Content dehumanizing a group of people based on their protected characteristics.\n",
      "- Hateful Imagery: Logos, symbols, or images promoting hostility against others based on protected characteristics (e.g., Nazi swastika, images depicting individuals as less than human).\n",
      "\n",
      "The following definitions and guidelines help classify text as implicit hate speech based on the nature of the language and intent:\n",
      "\n",
      "-Definition of Implicit Hate Speech: Indirect or coded language that conveys prejudicial attitudes without using overt slurs or explicit hate language.\n",
      "-Key Features of Implicit Hate Speech: Abstract or coded references to race, religion, or other protected characteristics. Sarcasm, misinformation, stereotypes, or appeals to racist attitudes without explicit language.\n",
      "\n",
      "\n",
      "Classification Rules\n",
      "\n",
      "If the text uses coded language, abstract references, stereotypes, or other indirect ways of promoting prejudice, classify it as Implicit Hate Speech.\n",
      "Ensure that the identification process considers the context to distinguish between harmful content and permissible expressions, such as consensual use of reclaimed slurs within a community.\n",
      "\n",
      "{tree_of_thoughts}\n",
      "\n",
      "Give in output \n",
      "1. the final classification as \"implicit_hate\" or \"not_hate\"  \n",
      "2. a confidence level between 0 and 1 for you classification\n",
      "3. an explanation of the most consistent reasoning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_stg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75fc459-d7f1-4852-97e8-2f74c2f7aea4",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f56bbfa-e7c2-4db8-bf44-777f391cb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hate_stg1 = pd.read_csv(data_folder + \"implicit_hate_test_stg1.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56060ffe-c0a8-4f45-aa8c-1aee31590a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "if debug_mode:\n",
    "    df_hate_stg1 = df_hate_stg1[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93250b90-5f52-457a-b7da-4b23ee73eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'deepseek' and not debug_mode:\n",
    "    df_hate_stg1 = df_hate_stg1[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b357d2e-d2a0-48e8-97b8-6f475037b2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_hate_stg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10bd43b-9a53-46ae-8b62-3d756f0a4f07",
   "metadata": {},
   "source": [
    "### Baseline with simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "953a4df9-40d5-494f-ab32-d349546ad98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_baseline = prompt_stg1.replace(\"{tree_of_thoughts}\", \"\")\n",
    "classify_stage_1(model, df_hate_stg1, prompt_baseline, result_baseline_stg1_file, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77785417-8da4-4c77-b5e7-42c9a1300fd4",
   "metadata": {},
   "source": [
    "### Prompt with tree of thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "976ce70f-74ac-4509-953f-cf959abdab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tot = prompt_stg1.replace(\"{tree_of_thoughts}\", tree_of_thoughts)\n",
    "classify_stage_1(model, df_hate_stg1, prompt_tot, result_prompt_tot_stg1_file, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c81c3-ddd9-4ef7-8dd8-fbf2933b602c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ade1dcfd-e3e7-42b3-8ca2-d50ed83dce1e",
   "metadata": {},
   "source": [
    "## Classification Stage 2: Fine-Grained Implicit Hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be58177b-5b82-456f-8613-f631dd5cd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitHateClassification(BaseModel):\n",
    "    implicit_class: Literal['white_grievance', 'irony', 'stereotypical', 'incitement', 'other', 'threatening', 'inferiority', 'other']\n",
    "    confidence: float\n",
    "    explanation : str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37639fa2-8dd7-4685-b6ab-38b60dcb51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_stage_2(model, df_hate, base_prompt, result_file, initialize = False):\n",
    "    \n",
    "    if initialize:\n",
    "        # Regenerate output file\n",
    "        df = pd.DataFrame(columns = ['post_id', 'implicit_class', 'confidence', 'explanation'])\n",
    "        df.to_csv(result_file, encoding = \"utf-8\", index = False)\n",
    "    else:\n",
    "        df_elab = pd.read_csv(result_file, encoding = \"utf-8\")\n",
    "        df_hate = df_hate[~df_hate['post_id'].isin(df_elab['post_id'])]\n",
    "        \n",
    "    parser = PydanticOutputParser(pydantic_object = ImplicitHateClassification)\n",
    "    prompt = get_prompt(base_prompt, parser)\n",
    "    chain = prompt | model | parser\n",
    "\n",
    "    for idx, row in df_hate.iterrows():\n",
    "        \n",
    "        try:            \n",
    "            time.sleep(wait_time)\n",
    "            result = chain.invoke({\"post\": row['post']})\n",
    "            \n",
    "            # Classification stage 2\n",
    "            new_row = {\n",
    "                'post_id': row['post_id'], \n",
    "                'implicit_class' : result.implicit_class, \n",
    "                'confidence' : result.confidence, \n",
    "                'explanation' : result.explanation\n",
    "            }\n",
    "            df = pd.DataFrame([new_row])\n",
    "            df.to_csv(result_file, encoding = \"utf-8\", mode='a', index=False, header=False)\n",
    "                      \n",
    "        except:\n",
    "          print(\"An exception occurred \" +  str(row['post_id']) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01425351-e586-46ea-8f4f-ced5e04fde39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompt_folder + 'prompt_stg2.txt') as f:\n",
    "    prompt_stg2 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2610f59e-c0de-458c-8f0d-07c328ffc70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following text has been categorized as \"implicit hate speech\", a more complex and subtle attack on a person or a group of people based on their protected characteristics without relying on explicit keywords.\n",
      "\n",
      "Evaluate the text against the following taxonomy to determine the most likely class.\n",
      "Class taxonomy of implicit hate speech:\n",
      "\n",
      "1. White Grievance: includes frustration over a minority group's perceived privilege and casting majority groups as the real victims of racism. This language is linked to extremist behavior and support for violence. An example is 'Black lives matter and white lives don't? Sounds racist.'\n",
      "2. Incitement to Violence: includes flaunting ingroup unity and power or elevating known hate groups and ideologies. Phrases like 'white brotherhood' operate in the former manner, while statements like 'Hitler was Germany Ã¢â‚¬â€œ Germans shall rise again!' operate in the latter, elevating nationalism and Nazism. Article 20 of the UN International Covenant on Civil and Political states that speech which incites violence shall be prohibited by law.\n",
      "3. Inferiority Language: implies one group or individual is inferior to another, and it can include dehumanization (denial of a person's humanity), and toxification (language that compares the target with disease, insects, animals), both of which are early warning signs of genocide. Inferiority language is also related to assaults on human dignity, dominance, and declarations of superiority of the in-group. For example, 'It's not a coincidence the best places to live are majority white.'\n",
      "4. Irony: refers to the use of sarcasm, humor, and satire to attack or demean a protected class or individual. For example, in the context of one hate group, the post 'Horrors... Disney will be forced into hiring Americans' works to discredit Disney for allegedly hiring only non-citizens or, really, nonwhites. Irony is not exempt from our hate speech typology, since it is commonly used by modern online hate groups to mask their hatred and extremism.\n",
      "5. Stereotypes and Misinformation: associate a protected class with negative attributes such as crime, or terrorism as in the rhetorical question, 'Can someone tell the black people in Chicago to stop killing one another before it becomes Detroit?' This class also includes misinformation that feeds stereotypes and vice versa, like holocaust denial and other forms of historical negationism.\n",
      "6. Threatening and Intimidation: convey a speaker commitment to a target's pain, injury, damage, loss, or violation of rights. While explicitly violent threats are well-recognized in the hate speech literature, here we highlight threats related to implicit violation of rights and freedoms, removal of opportunities, and more subtle forms of intimidation, such as 'All immigration of non-whites should be ended'.\n",
      "7. Other: none of the above was identified \n",
      "\n",
      "{tree_of_thoughts}\n",
      "\n",
      "Return in output\n",
      "\n",
      "1. the most probable class  \n",
      "2. a confidence level between 0 and 1 for you classification\n",
      "3. an explanation for you classification\n"
     ]
    }
   ],
   "source": [
    "print(prompt_stg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed58944f-29a8-4e78-8374-411f5725e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hate_stg2 = pd.read_csv(data_folder + \"implicit_hate_test_stg2.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85b75bfb-9933-4750-a1f8-da35bb0cbf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "if debug_mode:\n",
    "    df_hate_stg2 = df_hate_stg2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daa1929d-4669-47ac-8ba5-8ff6bbb5016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'deepseek' and not debug_mode:\n",
    "    df_hate_stg2 = df_hate_stg2.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc35d50-eed0-462e-b509-b13cba53509b",
   "metadata": {},
   "source": [
    "### Baseline with simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff911f6-b4d2-4e03-9839-f8fd3e1c8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_baseline = prompt_stg2.replace(\"{tree_of_thoughts}\", \"\")\n",
    "classify_stage_2(model, df_hate_stg2, prompt_baseline, result_baseline_stg2_file, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fedfc3-51b0-42dc-b0b3-7988144bf9d4",
   "metadata": {},
   "source": [
    "### Prompt with tree of thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48f6ed6c-d2a1-4bac-ac43-0eaf1ff134fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tot = prompt_stg2.replace(\"{tree_of_thoughts}\", tree_of_thoughts)\n",
    "classify_stage_2(model, df_hate_stg2, prompt_tot, result_prompt_tot_stg2_file, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a368b-716f-4e6b-906c-df2ff14fea63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f9fb30d-8844-4b90-af6a-8949ba36e554",
   "metadata": {},
   "source": [
    "## Classification Stage 3: Hate Targets and Implied Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e4576bb-cfa6-417a-866a-46f6a315d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImpliedMeaning(BaseModel):\n",
    "    targeted_group: str\n",
    "    implied_statement: str    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a69fa20-9a17-446f-ab5f-94a69ed2f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_stage_3(model, df_hate, base_prompt, result_file, initialize = False):\n",
    "    \n",
    "    if initialize:\n",
    "        # Regenerate output file\n",
    "        df = pd.DataFrame(columns = ['post_id', 'target', 'implied_statement'])\n",
    "        df.to_csv(result_file, encoding = \"utf-8\", index = False)\n",
    "    else:\n",
    "        df_elab = pd.read_csv(result_file, encoding = \"utf-8\")\n",
    "        df_hate = df_hate[~df_hate['post_id'].isin(df_elab['post_id'])]\n",
    "        \n",
    "    parser = PydanticOutputParser(pydantic_object = ImpliedMeaning)\n",
    "    prompt = get_prompt(base_prompt, parser)\n",
    "    chain = prompt | model | parser\n",
    "\n",
    "    for idx, row in df_hate.iterrows():\n",
    "        \n",
    "        try:            \n",
    "            time.sleep(wait_time)\n",
    "            result = chain.invoke({\"post\": row['post']})\n",
    "            \n",
    "            # Classification stage 2\n",
    "            new_row = {\n",
    "                'post_id': row['post_id'], \n",
    "                'target' : result.targeted_group, \n",
    "                'implied_statement' : result.implied_statement            \n",
    "            }\n",
    "            df = pd.DataFrame([new_row])\n",
    "            df.to_csv(result_file, encoding = \"utf-8\", mode='a', index=False, header=False)\n",
    "                      \n",
    "        except:\n",
    "          print(\"An exception occurred \" +  str(row['post_id']) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2deb3876-4e26-4b48-a13b-1287f90e25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompt_folder + 'prompt_stg3.txt') as f:\n",
    "    prompt_stg3 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3af3b731-3d20-4f30-bc0a-78b72f8a9808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following text has been categorized as \"implicit hate speech\", a more complex and subtle attack on a person or a group of people based on their protected characteristics without relying on explicit keywords.\n",
      "\n",
      "Your job is to infer both the targeted group (GROUP) and the stereotype, characteristic, or implication about that group expressed in the text. \n",
      "You have two tasks:\n",
      "\n",
      "Task 1: Identify the targeted group (GROUP).\n",
      "The group might be defined by characteristics such as ethnicity, religion, class, sexual orientation, immigration status, or similar traits. Examples of groups include:\n",
      "\n",
      "-Black folks\n",
      "-Asian folks\n",
      "-Muslims\n",
      "-Jews\n",
      "-Latino/Latina folks\n",
      "-Immigrants\n",
      "\n",
      "\n",
      "Task 2: Determine what stereotype, characteristic, or action is implied about the identified group.\n",
      "Using the group identified in Task 1, describe the implication using a simple phrase. Avoid copying text directly from the text. Examples of such phrases include:\n",
      "\n",
      "-[GROUP] do/does [action]\n",
      "-[GROUP] are [characteristic]\n",
      "-[GROUP] kill [action]\n",
      "-[GROUP] have [trait]\n",
      "-[GROUP] commit [action]\n",
      "\n",
      "For example:\n",
      "\n",
      "\"Women are ***.\"\n",
      "\"Immigrants take ***.\"\n",
      "\"Muslims kill ***.\"\n",
      "\"Liberals are ***.\"\n",
      "\n",
      "{tree_of_thoughts}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_stg3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c575f-ce97-49b5-97b5-7623cba950e9",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c1e26d-80d0-4139-8769-81d0bafb6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hate_stg3 = pd.read_csv(data_folder + \"implicit_hate_test_stg3.csv\", encoding=\"utf-8\")\n",
    "df_hate_stg3 = df_hate_stg3[['post_id', 'post']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c21f95b8-8907-4ba5-94b6-eb6298b4dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "if debug_mode:\n",
    "    df_hate_stg3 = df_hate_stg3[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf17e2-2209-49c4-8f52-e970a87b3651",
   "metadata": {},
   "source": [
    "### Baseline with simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28caa2f9-8f1f-4b6f-97c0-4f6461871d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_baseline = prompt_stg3.replace(\"{tree_of_thoughts}\", \"\")\n",
    "classify_stage_3(model, df_hate_stg3, prompt_baseline, result_baseline_stg3_file, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b18b22-4788-4502-b61d-9d54d99e74aa",
   "metadata": {},
   "source": [
    "### Prompt with tree of thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55cdd862-0096-4dc1-875d-2c7926e870eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tot = prompt_stg3.replace(\"{tree_of_thoughts}\", tree_of_thoughts)\n",
    "classify_stage_3(model, df_hate_stg3, prompt_tot, result_prompt_tot_stg3_file, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf7e40-4f53-4571-8ec7-588e5bf9cfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
