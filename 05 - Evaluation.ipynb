{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2378a39-1324-40e5-8338-5decf4e01f5b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9940154d-0bcd-4023-9e64-d6f311d741e0",
   "metadata": {},
   "source": [
    "References for text similarity metrics: \\\n",
    "[BLEU Score](https://towardsdatascience.com/foundations-of-nlp-explained-bleu-score-and-wer-metrics-1a5ba06d812b) -\n",
    "[ROUGE Score](https://medium.com/@eren9677/text-summarization-387836c9e178) -\n",
    "[NIST Score](https://aclanthology.org/www.mt-archive.info/HLT-2002-Doddington.pdf) -\n",
    "[METEOR Score](https://aclanthology.org/W05-0909.pdf) -\n",
    "[BERT Score](https://arxiv.org/pdf/1904.09675) -\n",
    "[BLEURT Score](https://aclanthology.org/2020.acl-main.704.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9c82c-106a-445d-9bbb-74f80e7f42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installazione di BLEURT\n",
    "#import os\n",
    "#!git clone https://github.com/google-research/bleurt.git\n",
    "#os.chdir('bleurt')\n",
    "#!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc157eb-5d58-4c53-a3c2-0dbffd9caa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.translate.nist_score import sentence_nist\n",
    "from rouge_score import rouge_scorer\n",
    "import bert_score\n",
    "from bleurt import score as bleurt_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "from transformers import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81500d-e1a5-44f2-9d9b-5c0003d4dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ee9dc-572a-4299-aa8b-a9c73fd7fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "result_folder = './results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f331345-6713-4a5f-a6bb-22bb340a7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mode = True # set to True to test evaluation of stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c98b04-90c7-415b-b37d-110ae6408531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mistral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d6132-435c-4f04-b71b-3818a19e901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'deepseek'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034b6f0-6ac7-4584-a895-be145627153e",
   "metadata": {},
   "source": [
    "# Evaluation Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937d923-ec23-4606-a799-7330bffcc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_stg1 = data_folder + \"implicit_hate_test_stg1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e9e61-cfb6-4351-8553-dc64da8cfe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stage_1(strategy, gold_file, pred_file):\n",
    "    \n",
    "    df_gold = pd.read_csv(gold_file, encoding = 'utf-8')\n",
    "    df_pred = pd.read_csv(pred_file, encoding = 'utf-8')\n",
    "\n",
    "    label_selector = ['implicit_hate', 'not_hate' ]\n",
    "    \n",
    "    df_gold = df_gold[df_gold['post_id'].isin(df_pred['post_id'])]\n",
    "    df_pred = df_pred[df_pred['post_id'].isin(df_gold['post_id'])]\n",
    "    \n",
    "    df_gold.sort_values(\"post_id\", axis=0, ascending=True, inplace=True)\n",
    "    df_pred.sort_values(\"post_id\", axis=0, ascending=True, inplace=True)\n",
    "    \n",
    "    labels_gold = df_gold['class']\n",
    "    predictions = df_pred['class']\n",
    "\n",
    "    f1_macro = f1_score(labels_gold, predictions, average = \"macro\")\n",
    "    accuracy = accuracy_score(labels_gold, predictions)\n",
    "    precision = precision_score(labels_gold, predictions, average = \"macro\")\n",
    "    recall = recall_score(labels_gold, predictions, average = \"macro\")\n",
    "    \n",
    "    clf_report = classification_report(labels_gold, predictions, labels = label_selector, target_names = label_selector, digits=4)\n",
    "    clf_report_dict = classification_report(labels_gold, predictions, labels = label_selector, target_names = label_selector,\n",
    "                                            digits=4, output_dict=True)\n",
    "    clf_report_df = pd.DataFrame(clf_report_dict)\n",
    "    \n",
    "    values_export = clf_report_df.loc[\"f1-score\", label_selector].T.values\n",
    "    values_export = \"\\t\".join([str(round(v,4)) for v in values_export])\n",
    "    \n",
    "    report = f\"\"\"F1-macro: {str(round(f1_macro, 4))} accuracy: {str(round(accuracy, 4))} precision: {str(round(precision, 4))} recall: {str(round(recall, 4))} \\n\\n{clf_report}\"\"\"\n",
    "\n",
    "    print(strategy + \": \" + report)    \n",
    "\n",
    "    confusion_matrix = metrics.confusion_matrix(labels_gold, predictions,labels = label_selector)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = label_selector)\n",
    "    cm_display.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "    return pd.DataFrame([{'Strategy' : strategy, \"F1-macro\" : f1_macro, 'Precision' : precision, 'Recall' : recall, 'Accuracy' : accuracy}])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fbe81c-8b7d-4f3b-8306-acc0223c055f",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa22017-5e2e-4616-9364-5b46d17837ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_stg1 = result_folder + model_name + \"_result_baseline_stg1.csv\"\n",
    "df_baseline_stg1 = evaluate_stage_1(\n",
    "    'Baseline', \n",
    "    test_file_stg1, \n",
    "    result_file_stg1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f31f69-a521-4794-b7f0-74f926e58d3d",
   "metadata": {},
   "source": [
    "### Prompt Tree of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f45e4-b4bb-4680-804f-86575377141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_stg1 = result_folder + model_name + \"_result_prompt_tot_stg1.csv\"\n",
    "df_prompt_tot_stg1 = evaluate_stage_1(\n",
    "    \"ToT Prompt\",\n",
    "    test_file_stg1, \n",
    "    result_file_stg1 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8930f88-b71d-4d03-a59c-e7baa7405b47",
   "metadata": {},
   "source": [
    "### Graph Tree of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b02310-a28e-4056-b3ef-c7ecb455fd5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_file_stg1 = result_folder + model_name + \"_result_graph_stg1.csv\"\n",
    "df_graph_stg1 = evaluate_stage_1(\n",
    "    \"ToT Graph\", \n",
    "    test_file_stg1, \n",
    "    result_file_stg1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444abe4-7b06-4359-9cc7-aa9229846f23",
   "metadata": {},
   "source": [
    "### Optimizer MIPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ece41c-ea61-473c-8e28-70c66a5fa0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_stg1 = result_folder + model_name + \"_result_optimizer_stg1.csv\"\n",
    "df_optim_stg1 = evaluate_stage_1(\n",
    "    \"Optimization Mipro\", \n",
    "    test_file_stg1, \n",
    "    result_file_stg1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7019f85-d29c-4362-850a-45bad2782a3c",
   "metadata": {},
   "source": [
    "## Results Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6dc29f-b53c-48f8-b15d-25c09f7ffdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_stg1 = pd.concat([df_baseline_stg1, df_prompt_tot_stg1, df_graph_stg1, df_optim_stg1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fff1ce-9e91-4a43-b8a3-4c3e3d1794f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_stg1.to_excel(result_folder + model_name + '_evaluation_stg1.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0da37a-3193-40ef-bf27-843c89b16dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_stg1 = pd.read_excel(result_folder + model_name + '_evaluation_stg1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ecc56-4d2d-41ad-9e8c-88eea714a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_stg1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023f19e-3a98-4ba0-a2a4-c7605f092075",
   "metadata": {},
   "source": [
    "### Qualitative analysis (MIPRO results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376785e8-5c1a-4a96-b044-c45bbd2b457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold_stg1 = pd.read_csv(data_folder + \"implicit_hate_test_stg1.csv\", encoding = 'utf-8')\n",
    "df_pred_stg1 = pd.read_csv(result_folder + model_name + \"_result_optimizer_stg1.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa97510e-8c1e-45cb-a904-0e68a8803bbb",
   "metadata": {},
   "source": [
    "#### Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec5992-6b09-4589-92d7-eb0123c2a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pred_stg1['confidence'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52579b1b-9e3f-41c1-a2e6-33b04d8b0177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_stg1.rename(columns={'class': 'class_pred'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24767a-e33c-49d0-bb60-aeb023e07139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_stg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599eed8e-5e1d-479e-a6dd-079bbb290df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_stg1 = pd.merge(df_gold_stg1, df_pred_stg1, on = 'post_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44704930-e596-434f-bd56-e81e2e17adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_stg1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07908a3a-6161-4b0b-9bf2-6e219c1a35a5",
   "metadata": {},
   "source": [
    "#### Confidence of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a642f-d513-4fc6-8f9f-ae13728e3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merge_stg1[df_merge_stg1['class'] == df_merge_stg1['class_pred']]['confidence'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fca75c-2f54-4645-826d-3dc8df177475",
   "metadata": {},
   "source": [
    "#### Confidence of wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15b298-6104-492c-8368-101b2092d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merge_stg1[df_merge_stg1['class'] != df_merge_stg1['class_pred']]['confidence'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3505d3e-919d-4a2d-b6b9-e94f800e3b1d",
   "metadata": {},
   "source": [
    "#### Examples of misclassified not hate posts with explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e6cd5-2db1-4e33-87a6-f15da96faca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp = df_merge_stg1[(df_merge_stg1['class'] == 'not_hate') & (df_merge_stg1['class_pred'] == 'implicit_hate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7390581-1914-4652-916f-4822c88e73b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_fp.sample(10).iterrows():\n",
    "    print('\\nPost: ' + row['post'])\n",
    "    print('Confidence: ' + str(row['confidence']))\n",
    "    print('Explanation: ' + row['explanation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b2691-9e7f-4d0f-81d8-71e283a43020",
   "metadata": {},
   "source": [
    "#### Was deepening used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969b1d1-4b4a-4401-ac20-fce3fe9e9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, TypedDict, Literal\n",
    "\n",
    "class HateClassification(BaseModel):\n",
    "    hate_class: Literal['implicit_hate','not_hate']\n",
    "    interpretations : Optional[str]\n",
    "    explanation : Optional[str]\n",
    "    confidence : Optional[float]\n",
    "    recursion_level : int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2667af2-ad62-42b0-aadc-933487c97160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resp = pd.DataFrame(columns = ['post', 'explanation', 'recursion_level'])\n",
    "files = glob.glob(result_folder + '/responses/*.json')\n",
    "\n",
    "for filename in files:\n",
    "    try: \n",
    "        with open(filename, 'r') as f:\n",
    "            text = f.read()\n",
    "            obj = json.loads(text)\n",
    "            hate = eval(obj['hate_class']['repr'])\n",
    "            new_row = {\n",
    "                'post': obj['post'], \n",
    "                'explanation' : hate.explanation, \n",
    "                'recursion_level' : hate.recursion_level\n",
    "            }\n",
    "            df_resp = pd.concat([df_resp, pd.DataFrame([new_row])])\n",
    "    except:\n",
    "        print(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f497c0-9e32-40cd-9f19-c2c547cfe385",
   "metadata": {},
   "source": [
    "#### Deepening was never used :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4dc84-5acc-42f6-9e32-f07e7251c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resp[df_resp['recursion_level'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643cc4b-a894-4105-a683-0fdfe73de9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84e12011-31bd-4581-bc8d-6b6e76550a09",
   "metadata": {},
   "source": [
    "# Evaluation Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f8349-0493-40ee-8109-ed221b6bee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_stg2 = data_folder + \"implicit_hate_test_stg2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27edc7-e200-40e2-8eaf-b8f9b47e3b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stage_2(strategy, gold_file, pred_file):\n",
    "\n",
    "    df_gold = pd.read_csv(gold_file, encoding = \"utf-8\")\n",
    "    df_pred = pd.read_csv(pred_file, encoding = \"utf-8\")\n",
    "    \n",
    "    label_selector = ['incitement', 'white_grievance', 'inferiority', 'stereotypical', 'irony', 'threatening', 'other']\n",
    "    \n",
    "    df_gold = df_gold[df_gold['post_id'].isin(df_pred['post_id'])]\n",
    "    df_pred = df_pred[df_pred['post_id'].isin(df_gold['post_id'])]\n",
    "    \n",
    "    df_gold.sort_values(\"post_id\", axis=0, ascending=True, inplace=True)\n",
    "    df_pred.sort_values(\"post_id\", axis=0, ascending=True, inplace=True)\n",
    "        \n",
    "    labels_gold = df_gold['implicit_class']\n",
    "    predictions = df_pred['implicit_class']\n",
    "    \n",
    "    f1_macro = f1_score(labels_gold, predictions, average = \"macro\")\n",
    "    accuracy = accuracy_score(labels_gold, predictions)\n",
    "    precision = precision_score(labels_gold, predictions, average = \"macro\")\n",
    "    recall = recall_score(labels_gold, predictions, average = \"macro\")\n",
    "    \n",
    "    clf_report = classification_report(labels_gold, predictions, labels = label_selector, target_names = label_selector, digits=4)\n",
    "    clf_report_dict = classification_report(labels_gold, predictions, labels = label_selector, target_names = label_selector,\n",
    "                                            digits=4, output_dict=True)\n",
    "    clf_report_df = pd.DataFrame(clf_report_dict)\n",
    "    \n",
    "    values_export = clf_report_df.loc[\"f1-score\", label_selector].T.values\n",
    "    values_export = \"\\t\".join([str(round(v,4)) for v in values_export])\n",
    "    \n",
    "    report = f\"\"\"F1-macro: {str(round(f1_macro, 4))} accuracy: {str(round(accuracy, 4))} precision: {str(round(precision, 4))} recall: {str(round(recall, 4))} \\n\\n{clf_report}\n",
    "    \"\"\"\n",
    "    print(strategy + \": \" + report)\n",
    "    print(values_export)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Compute the confusion matrix\n",
    "    cm = metrics.confusion_matrix(labels_gold, predictions, labels = label_selector)\n",
    "    \n",
    "    # Plot the confusion matrix with percentages\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    # We want to show all ticks and label them with the respective list entries\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=label_selector, yticklabels=label_selector,\n",
    "           title='Implicit hate classification',\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations\n",
    "    fmt = '.0f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"#274c81\")\n",
    "    #fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return pd.DataFrame([{'Strategy' : strategy, \"F1-macro\" : f1_macro, 'Precision' : precision, 'Recall' : recall, 'Accuracy' : accuracy}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6331dd2-84ce-46f8-8273-05f62b24327e",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5c4ba-7d07-48dd-bc91-c52f138a49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_stg2 = result_folder + model_name + \"_result_baseline_stg2.csv\"\n",
    "df_baseline_stg2 = evaluate_stage_2(\n",
    "    \"Baseline\",\n",
    "    test_file_stg2,\n",
    "    result_file_stg2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9ee69-20e0-4877-aaaf-fd04e7efa76d",
   "metadata": {},
   "source": [
    "### Prompt Tree of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3daa11a-0c07-46d9-9ae0-534258159789",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_stg2 = result_folder + model_name + \"_result_prompt_tot_stg2.csv\"\n",
    "df_prompt_tot_stg2 = evaluate_stage_2(\n",
    "    \"Prompt ToT\",\n",
    "    test_file_stg2,\n",
    "    result_file_stg2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2d590-346b-4e22-9c14-4bcbe1829958",
   "metadata": {},
   "source": [
    "### Graph Tree of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1404f3-7f33-4244-b889-3dd528777142",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_stg2 = result_folder + model_name + \"_result_graph_stg2.csv\"\n",
    "df_graph_stg2 = evaluate_stage_2(\n",
    "    \"Graph ToT\",\n",
    "    test_file_stg2,\n",
    "    result_file_stg2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ce36e-94be-4d87-8cfb-f830e4424afd",
   "metadata": {},
   "source": [
    "### Optimizer MIPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6539378-52aa-4908-9992-5a35e79e4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_stg2 = result_folder + model_name + \"_result_optimizer_stg2.csv\"\n",
    "df_optim_stg2 = evaluate_stage_2(\n",
    "    \"Optimizer\",\n",
    "    test_file_stg2,\n",
    "    result_file_stg2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da2c35-d054-45dc-b2bb-0c603b2515d1",
   "metadata": {},
   "source": [
    "## Final results Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b440f0-b116-4698-895e-ee2f819f6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_stg2 = pd.concat([df_baseline_stg2, df_prompt_tot_stg2, df_graph_stg2, df_optim_stg2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78205a67-683b-491a-b6ca-34787185adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_stg2.to_excel(result_folder +  model_name + '_evaluation_stg2.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bed0f2-6154-4e16-a297-622c8fd8b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_stg2 = pd.read_excel(result_folder + model_name + '_evaluation_stg2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed4ddb-0c53-41fd-8e64-85b267a4c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_stg2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93875ab-9530-4d61-83eb-1fd8ff00abb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2191abcc-b6d3-4361-a62b-ab4d6c105f1f",
   "metadata": {},
   "source": [
    "### Qualitative analysis (results of MIPRO optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23aa4e4-177c-496e-b3a0-a74afa012413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold_stg2 = pd.read_csv(data_folder + \"implicit_hate_test_stg2.csv\", encoding = 'utf-8')\n",
    "df_pred_stg2 = pd.read_csv(result_folder + model_name + \"_result_optimizer_stg2.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db199d5c-08c3-472d-8925-188a5968a7f0",
   "metadata": {},
   "source": [
    "#### Overall confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28c357-51c3-4cd8-8de2-6e40be392978",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pred_stg2['confidence'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee378ddc-e90a-41d4-8cbf-da2b5fbf0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_stg2.rename(columns={'implicit_class': 'implicit_class_pred'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635c7a6-a89a-499f-9938-5f01955b7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_stg2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1dd13-ff2b-4811-885d-3194ec1cc01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_stg2 = pd.merge(df_gold_stg2, df_pred_stg2, on = 'post_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11bf26-3dab-4b73-83d3-df1f53ae9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_stg2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd75a5d9-44e4-4190-b611-7ba190d2fb45",
   "metadata": {},
   "source": [
    "#### Confidence of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943949d5-9bd8-4a80-a05a-c2ebb891071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merge_stg2[df_merge_stg2['implicit_class'] == df_merge_stg2['implicit_class']]['confidence'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bac4df-ec1f-4e61-b557-ff0108f37359",
   "metadata": {},
   "source": [
    "#### Confidence of wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c375f-7a58-4136-86ee-4c8b2747da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merge_stg2[df_merge_stg2['implicit_class'] != df_merge_stg2['implicit_class_pred']]['confidence'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c579e51-1ec6-49b0-8ed5-ce97af3c2e47",
   "metadata": {},
   "source": [
    "#### Examples of misclassified posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922d889-6387-4987-ad26-dc2ed98559ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_errors = df_merge_stg2[df_merge_stg2['implicit_class'] != df_merge_stg2['implicit_class_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb713b-a118-457d-a90e-946cb93565aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_errors.sample(10).iterrows():\n",
    "    print('\\nPost: ' + row['post'])\n",
    "    print('Confidence: ' + str(row['confidence']) + ' - Gold class: ' + row['implicit_class'] +' - Pred class: ' + row['implicit_class_pred'])\n",
    "    print('Explanation: ' + row['explanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cfd6da-11f7-4700-9d4c-927e4e7fa3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f4742-f02b-4fe9-8238-f6996d8a0694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64ffb179-8774-4568-97cd-b91eed1906c9",
   "metadata": {},
   "source": [
    "# Evaluation Stage 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9858de74-9c42-45cc-bfe5-873c6319bc2b",
   "metadata": {},
   "source": [
    "[BLEURT installation](https://github.com/google-research/bleurt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ff5ed-107e-4b41-ad0b-6ca7725d01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BLEURT Scorer\n",
    "checkpoint =  \"../bleurt/bleurt/BLEURT-20\"\n",
    "bleurt_scorer = bleurt_score.BleurtScorer(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99f3ce-d435-4460-90b6-a82de7588517",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_stg3 = data_folder + 'implicit_hate_test_stg3.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2181f5-125b-4f72-9a29-0708efbeb4b6",
   "metadata": {},
   "source": [
    "### Text similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e35137-45bf-4369-8b6b-82b4056b32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_metrics(generated, reference, bleurt_scorer, bert_lang='en'):\n",
    "\n",
    "    generated_tokens = nltk.word_tokenize(generated.lower())\n",
    "    reference_tokens = nltk.word_tokenize(reference.lower())\n",
    "\n",
    "    # Compute BLEU Score\n",
    "\n",
    "    # Smoothing method1: adds 1 to the numerator and denominator for higher-order n-grams with no matches, akin to additive smoothing.\n",
    "    # Works well for very short sentences or cases with few matches.\n",
    "    smoothing = SmoothingFunction().method1\n",
    "\n",
    "    bleu = sentence_bleu([reference_tokens], generated_tokens, smoothing_function = smoothing)\n",
    "    bleu_1 = sentence_bleu([reference_tokens], generated_tokens, weights=(1, 0, 0, 0), smoothing_function = smoothing)\n",
    "    bleu_2 = sentence_bleu([reference_tokens], generated_tokens, weights=(0.5, 0.5, 0, 0), smoothing_function = smoothing) # Cumulative\n",
    "\n",
    "    # Compute ROUGE Score (F1)\n",
    "    rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = rouge_scorer_obj.score(reference, generated)\n",
    "    rouge_f1 = {\n",
    "        'ROUGE-1': rouge_scores['rouge1'].fmeasure,\n",
    "        'ROUGE-2': rouge_scores['rouge2'].fmeasure,\n",
    "        'ROUGE-L': rouge_scores['rougeL'].fmeasure\n",
    "    }\n",
    "    # Compute METEOR Score\n",
    "    meteor = meteor_score([reference_tokens], generated_tokens)\n",
    "\n",
    "    # Compute NIST Score\n",
    "    n = np.min((len(reference_tokens),len(generated_tokens),2))\n",
    "    nist = sentence_nist([reference_tokens], generated_tokens, n = n)\n",
    "\n",
    "    # Compute BERTScore (F1)\n",
    "    P, R, F1 = bert_score.score([generated], [reference], lang=bert_lang, verbose=False)\n",
    "    bert_f1 = F1.mean().item()\n",
    "\n",
    "    # Compute BLUERT score\n",
    "    bleurt_scores = bleurt_scorer.score(references = [reference], candidates = [generated])\n",
    "    if isinstance(bleurt_scores, list) and len(bleurt_scores) == 1:\n",
    "        bleurt = bleurt_scores[0]\n",
    "    else:\n",
    "        0\n",
    "\n",
    "    # Combine scores\n",
    "    return {\n",
    "        'BLEU-1' : bleu_1,\n",
    "        'BLEU-2' : bleu_2,\n",
    "        'BLEU': bleu,\n",
    "        **rouge_f1,\n",
    "        'METEOR' : meteor,\n",
    "        'NIST' : nist,\n",
    "        'BERTScore': bert_f1,\n",
    "        'BLEURTScore' : bleurt\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426eae2-b1b7-4c89-8e39-1da02b78fbde",
   "metadata": {},
   "source": [
    "## Target similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c017020-9273-4533-a6de-f8f77ec2d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target_similarity(strategy, gold_file, pred_file, bleurt_scorer, debug_mode = False):\n",
    "\n",
    "    df_gold = pd.read_csv(gold_file, encoding=\"utf-8\")\n",
    "    df_pred = pd.read_csv(pred_file, encoding=\"utf-8\")    \n",
    "    \n",
    "    df_pred = df_pred[df_pred['target'].notnull()]\n",
    "    df_pred = df_pred[df_pred['target'].notna()] \n",
    "    \n",
    "    if debug_mode:\n",
    "        df_pred = df_pred.sample(2)\n",
    "    \n",
    "    df_gold.rename(columns={'target': 'target_gold'}, inplace=True)\n",
    "    df_pred.rename(columns={'target': 'target_pred'}, inplace=True)\n",
    "    \n",
    "    df_gold = df_gold[df_gold['post_id'].isin(df_pred['post_id'])]\n",
    "    df_pred = df_pred[df_pred['post_id'].isin(df_gold['post_id'])]\n",
    "    \n",
    "    df_gold.sort_values(\"post_id\", axis=0, ascending=True, inplace=True)\n",
    "    df_pred.sort_values(\"post_id\", axis=0, ascending=True, inplace=True)\n",
    "    \n",
    "    df_merge = pd.merge(df_gold, df_pred, on = \"post_id\")\n",
    "    df_target = df_merge[['post_id', 'post', 'target_gold', 'target_pred']]\n",
    "    \n",
    "    # Compute metrics\n",
    "    similarity_metrics = df_target.apply(lambda row: compute_similarity_metrics(row['target_pred'], row['target_gold'], bleurt_scorer), axis=1)\n",
    "    \n",
    "    # Flatten the metrics into separate columns\n",
    "    metrics_df = pd.DataFrame(similarity_metrics.tolist())\n",
    "    \n",
    "    # Combine the original DataFrame with the metrics\n",
    "    df_target_result = pd.concat([df_target, metrics_df], axis=1)\n",
    "    df_target_result_max = df_target_result.groupby('post_id')[df_target_result.columns[4: ].tolist()].max()\n",
    "    \n",
    "    # Average results\n",
    "    df_result = df_target_result_max[1: ].mean().to_frame().T\n",
    "    df_result.insert(loc = 0, column = 'Strategy', value = strategy)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e9c05-962b-468f-bb3b-da0c8d1fec18",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72029af-00d0-4d99-bc73-69a34b106728",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_similiarty_baseline = compute_target_similarity(\n",
    "    'Baseline',\n",
    "    result_file_stg3,\n",
    "    result_folder + model_name + '_result_baseline_stg3.csv',\n",
    "    bleurt_scorer,\n",
    "    debug_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443245d0-859e-4530-91ad-fe3decb9b69a",
   "metadata": {},
   "source": [
    "### Prompt Tree of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed52458-45eb-49f8-8a9a-18fb9388e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_similiarty_prompt_tot = compute_target_similarity(\n",
    "    'Prompt ToT',\n",
    "    result_file_stg3,\n",
    "    result_folder + model_name + '_result_prompt_tot_stg3.csv',\n",
    "    bleurt_scorer,\n",
    "    debug_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187987ec-71e1-45d2-8144-f48a3c547c3a",
   "metadata": {},
   "source": [
    "### Graph Tree of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adc6bf4-279b-42c4-b2cc-0474f0fde9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_similiarty_graph = compute_target_similarity(\n",
    "    'Graph ToT',\n",
    "    result_file_stg3,\n",
    "    result_folder + model_name + '_result_graph_stg3.csv',\n",
    "    bleurt_scorer,\n",
    "    debug_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2301587-5a5a-484d-9635-5ecbbcd3f20f",
   "metadata": {},
   "source": [
    "### Otimizer MIPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1466f9d-f9d8-4570-9490-dc09cb1ca8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_similiarty_optimized = compute_target_similarity(\n",
    "    'Optimized',\n",
    "    result_file_stg3,\n",
    "    result_folder + model_name + '_result_optimizer_stg3.csv',\n",
    "    bleurt_scorer,\n",
    "    debug_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092bf7d1-ec4e-4e19-a19e-9b996de14db6",
   "metadata": {},
   "source": [
    "## Result Target similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e62a8-820d-49e5-aa7c-23d4c6f8ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_similarity_result = pd.concat(\n",
    "    [target_similiarty_baseline, \n",
    "     target_similiarty_prompt_tot, \n",
    "     target_similiarty_graph, \n",
    "     target_similiarty_optimized]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608e9c2-4b5d-42c5-aa4e-cd52e795baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode == False:\n",
    "    target_similarity_result.to_excel(result_folder + model_name + '_evaluation_stg3_target.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671faae-b8bc-401c-8f69-27a3b14065b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_similarity_result = pd.read_excel(result_folder + model_name + '_evaluation_stg3_target.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ddab5-0934-4630-a26b-7492ccd63413",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_similarity_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2588d02b-b695-4764-9ddf-a2959cb80363",
   "metadata": {},
   "source": [
    "## Meaning similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83c97d-6754-4362-af1c-63edb834b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meaning_similarity(strategy, gold_file, pred_file, bleurt_scorer, debug_mode = False):\n",
    "\n",
    "    df_gold = pd.read_csv(gold_file, encoding=\"utf-8\")\n",
    "    df_pred = pd.read_csv(pred_file, encoding=\"utf-8\")\n",
    "\n",
    "    df_pred = df_pred[df_pred['implied_statement'].notnull()]\n",
    "    df_pred = df_pred[df_pred['implied_statement'].notna()]    \n",
    "    \n",
    "    if debug_mode:\n",
    "        df_pred = df_pred.sample(2)\n",
    "        \n",
    "    df_gold.rename(columns={'implied_statement': 'implied_statement_gold'}, inplace=True)\n",
    "    df_pred.rename(columns={'implied_statement': 'implied_statement_pred'}, inplace=True)\n",
    "    \n",
    "    df_gold = df_gold[df_gold['post_id'].isin(df_pred['post_id'])]\n",
    "    df_pred = df_pred[df_pred['post_id'].isin(df_gold['post_id'])]\n",
    "    \n",
    "    df_gold.sort_values(\"post_id\", axis=0, ascending=True, inplace=True)\n",
    "    df_pred.sort_values(\"post_id\", axis=0, ascending=True, inplace=True)\n",
    "    \n",
    "    df_merge = pd.merge(df_gold, df_pred, on = \"post_id\")\n",
    "    df_meaning = df_merge[['post_id', 'post', 'implied_statement_gold', 'implied_statement_pred']]\n",
    "    \n",
    "    # Compute metrics\n",
    "    similarity_metrics = df_meaning.apply(lambda row: compute_similarity_metrics(row['implied_statement_pred'], row['implied_statement_gold'], bleurt_scorer), axis=1)\n",
    "    \n",
    "    # Flatten the metrics into separate columns\n",
    "    metrics_df = pd.DataFrame(similarity_metrics.tolist())\n",
    "    \n",
    "    # Combine the original DataFrame with the metrics\n",
    "    df_meaning_result = pd.concat([df_meaning, metrics_df], axis=1)\n",
    "    df_meaning_result_max = df_meaning_result.groupby('post_id')[df_meaning_result.columns[4: ].tolist()].max()\n",
    "    \n",
    "    # Average results\n",
    "    df_result = df_meaning_result_max[1: ].mean().to_frame().T\n",
    "    df_result.insert(loc = 0, column = 'Strategy', value = strategy)\n",
    "\n",
    "    return df_result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6d1e7-c3f1-442e-b8a2-90be626e64d4",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b0b48-ee9f-4a3d-a0b5-38c1be53c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meaning_similiarty_baseline = compute_meaning_similarity(\n",
    "    'Baseline',\n",
    "    result_file_stg3,\n",
    "    result_folder + model_name + '_result_baseline_stg3.csv',\n",
    "    bleurt_scorer,\n",
    "    debug_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb403e0-3845-4848-b13d-b3160310a6eb",
   "metadata": {},
   "source": [
    "### Prompt Tree of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7490d0-da71-44e1-ab00-f622db808b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "meaning_similiarty_prompt_tot = compute_meaning_similarity(\n",
    "    'Prompt ToT',\n",
    "    result_file_stg3,\n",
    "    result_folder +  model_name + '_result_prompt_tot_stg3.csv',\n",
    "    bleurt_scorer,\n",
    "    debug_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6dd427-7b38-4b90-b537-1926f5803f3a",
   "metadata": {},
   "source": [
    "### Graph Tree of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a34976-ce55-4b3b-8d40-2281d2922e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "meaning_similiarty_graph = compute_meaning_similarity(\n",
    "    'Graph ToT',\n",
    "    result_file_stg3,\n",
    "    result_folder + model_name + '_result_graph_stg3.csv',\n",
    "    bleurt_scorer,\n",
    "    debug_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea9527-6f8c-4362-bd8c-a11691d9bc7c",
   "metadata": {},
   "source": [
    "### Optimizer MIPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd18703-5278-4645-abd9-c47b0d6265f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meaning_similiarty_optimized = compute_meaning_similarity(\n",
    "    'Optimized',\n",
    "    result_file_stg3,\n",
    "    result_folder + model_name + '_result_optimizer_stg3.csv',\n",
    "    bleurt_scorer,\n",
    "    debug_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc03852-ec38-4bf2-a052-58e89ff0a8a9",
   "metadata": {},
   "source": [
    "## Results Meaning similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524b153-d01f-4a1c-8348-a315f31f204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meaning_similarity_result = pd.concat(\n",
    "    [meaning_similiarty_baseline,\n",
    "     meaning_similiarty_prompt_tot, \n",
    "     meaning_similiarty_graph, \n",
    "     meaning_similiarty_optimized]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76531402-cfcf-4e02-87f1-975253bd8a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode == False:\n",
    "    meaning_similarity_result.to_excel(result_folder + model_name + '_evaluation_stg3_meaning.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4373e25a-0d17-42c8-8a1a-814643049a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meaning_similarity_result = pd.read_excel(result_folder + model_name + '_evaluation_stg3_meaning.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e1eeb-95be-4129-8c3d-fec3e0030163",
   "metadata": {},
   "outputs": [],
   "source": [
    "meaning_similarity_result.round(3).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794d84f-236d-4940-9fb1-f0c1c00284ca",
   "metadata": {},
   "source": [
    "### Qualitative analysis (target, MIPRO results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49e73e-370d-4455-a4a2-b8b7ba90e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold_stg3 = pd.read_csv(\"./implicit-hate-data/implicit_hate_test_stg3.csv\", encoding = 'utf-8')\n",
    "df_pred_stg3 = pd.read_csv(\"./implicit-hate-results/\" + model_name + \"_result_optimizer_stg3.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567797a-2761-46ee-9928-01d13a5989a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold_stg3['target'] = df_gold_stg3['target'].str.lower()\n",
    "df_pred_stg3['target'] = df_pred_stg3['target'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b22d91-9fb2-4de3-96ab-fa8bd91a5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df_gold_stg3.groupby(['target'])['post_id'].count().div(len(df_gold_stg3)).multiply(100).sort_values().tail(15).plot(\n",
    "    kind = 'barh', \n",
    "    xlabel='Number of posts (%)', \n",
    "    ylabel = 'Target',  \n",
    "    title = 'Most frequent targets \\n'\n",
    ")                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20806c92-a1ff-4887-9685-8f1389cbe851",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df_pred_stg3.groupby(['target'])['post_id'].count().div(len(df_pred_stg3)).multiply(100).sort_values().tail(15).plot(\n",
    "    kind = 'barh', \n",
    "    xlabel='Number of posts (%)', \n",
    "    ylabel = 'Target',  \n",
    "    title = 'Most predicted targets \\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072a6fc-d37d-45be-aada-883d463d43c5",
   "metadata": {},
   "source": [
    "#### Immigrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46341d-3ed9-42c2-bbf8-6cc2c1471e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigrants = df_gold_stg3[df_gold_stg3['target'] == 'immigrants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1047f0-611d-4563-ba69-f737a7cef973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_immigrants = df_pred_stg3[df_pred_stg3['post_id'].isin(df_immigrants['post_id'])]\n",
    "df_pred_immigrants = df_pred_immigrants[df_pred_immigrants['target'] != 'immigrants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08873fa1-a29e-4a0b-bb90-5d963402e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df_pred_immigrants.groupby(['target'])['post_id'].count().sort_values().tail(10).plot(\n",
    "    kind = 'barh', \n",
    "    xlabel='Number of posts', \n",
    "    ylabel = 'Target',  \n",
    "    title = 'Most frequent targets \\n'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f58dd-11d5-481e-ada6-2f6f10ad8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_immigrants[df_pred_immigrants['target'] != 'immigrants'].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81168ff8-6511-4d17-b1b7-c03c042f533a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
